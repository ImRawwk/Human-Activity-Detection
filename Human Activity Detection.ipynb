{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Activity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hims1\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hims1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\hims1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hims1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 1.3312 - acc: 0.4323 - val_loss: 1.1683 - val_acc: 0.4846\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.0265 - acc: 0.5618 - val_loss: 0.9187 - val_acc: 0.5945\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.8139 - acc: 0.6488 - val_loss: 0.7853 - val_acc: 0.6193\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.7096 - acc: 0.6689 - val_loss: 0.7408 - val_acc: 0.6159\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.6401 - acc: 0.6880 - val_loss: 0.7020 - val_acc: 0.6664\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.6230 - acc: 0.6979 - val_loss: 0.7287 - val_acc: 0.7017\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.5834 - acc: 0.7262 - val_loss: 0.6355 - val_acc: 0.7268\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.5487 - acc: 0.7481 - val_loss: 0.6564 - val_acc: 0.7306\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.4930 - acc: 0.7803 - val_loss: 0.6182 - val_acc: 0.7360\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.4556 - acc: 0.7900 - val_loss: 0.5948 - val_acc: 0.7112\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.4074 - acc: 0.8039 - val_loss: 0.5054 - val_acc: 0.7421\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.3793 - acc: 0.8252 - val_loss: 0.4603 - val_acc: 0.7808\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 0.3665 - acc: 0.8630 - val_loss: 0.5039 - val_acc: 0.8612\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.3789 - acc: 0.8876 - val_loss: 0.4645 - val_acc: 0.8480\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.3372 - acc: 0.9055 - val_loss: 0.4003 - val_acc: 0.8687\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.2673 - acc: 0.9210 - val_loss: 0.4191 - val_acc: 0.8473\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.2368 - acc: 0.9236 - val_loss: 0.3641 - val_acc: 0.8867\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.2131 - acc: 0.9323 - val_loss: 0.4253 - val_acc: 0.8833- lo - ETA: 6s - loss: 0.2143  -\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.2135 - acc: 0.9347 - val_loss: 0.3123 - val_acc: 0.8985\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1983 - acc: 0.9407 - val_loss: 0.4502 - val_acc: 0.8914\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.2383 - acc: 0.9308 - val_loss: 0.3462 - val_acc: 0.8931\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1764 - acc: 0.9441 - val_loss: 0.4002 - val_acc: 0.8958\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1920 - acc: 0.9406 - val_loss: 0.5881 - val_acc: 0.8850lo\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.2227 - acc: 0.9361 - val_loss: 0.3583 - val_acc: 0.8992\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1895 - acc: 0.9421 - val_loss: 0.4919 - val_acc: 0.8748\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1905 - acc: 0.9438 - val_loss: 0.3812 - val_acc: 0.8826\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1918 - acc: 0.9416 - val_loss: 0.4873 - val_acc: 0.8951\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1648 - acc: 0.9463 - val_loss: 0.3695 - val_acc: 0.8992\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1799 - acc: 0.9442 - val_loss: 0.4771 - val_acc: 0.8884\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1605 - acc: 0.9465 - val_loss: 0.4689 - val_acc: 0.8965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6df593eb8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         1        0                   0   \n",
      "SITTING                  0      419        51        0                   1   \n",
      "STANDING                 0      132       397        2                   0   \n",
      "WALKING                  0        0         0      466                  29   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 416   \n",
      "WALKING_UPSTAIRS         0        1         0       22                  14   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            26  \n",
      "SITTING                           20  \n",
      "STANDING                           1  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 3  \n",
      "WALKING_UPSTAIRS                 434  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 415us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46892408261934193, 0.8965049202578894]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment - Hyperparameter Tune LSTM model for better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with different number of LSTM units "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1. with 40 LSTM units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 40)                8000      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 246       \n",
      "=================================================================\n",
      "Total params: 8,246\n",
      "Trainable params: 8,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 1.3119 - acc: 0.4222 - val_loss: 1.2055 - val_acc: 0.4452\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 1.0675 - acc: 0.5169 - val_loss: 1.0054 - val_acc: 0.5680\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.9326 - acc: 0.5714 - val_loss: 0.9127 - val_acc: 0.5653\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.8286 - acc: 0.6221 - val_loss: 0.9601 - val_acc: 0.5253\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.7166 - acc: 0.6884 - val_loss: 0.7821 - val_acc: 0.6797\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.5785 - acc: 0.7824 - val_loss: 0.9842 - val_acc: 0.6922\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.5031 - acc: 0.8255 - val_loss: 0.6473 - val_acc: 0.7998\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.3928 - acc: 0.8694 - val_loss: 0.5782 - val_acc: 0.8283\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.3358 - acc: 0.8891 - val_loss: 0.6768 - val_acc: 0.8005\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2934 - acc: 0.9072 - val_loss: 0.4664 - val_acc: 0.8331\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.2705 - acc: 0.9153 - val_loss: 0.4192 - val_acc: 0.8585\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2342 - acc: 0.9246 - val_loss: 0.4459 - val_acc: 0.8694\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2426 - acc: 0.9215 - val_loss: 0.8984 - val_acc: 0.7669\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2252 - acc: 0.9300 - val_loss: 0.6818 - val_acc: 0.8449\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2385 - acc: 0.9263 - val_loss: 0.6424 - val_acc: 0.8616\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2598 - acc: 0.9161 - val_loss: 0.4361 - val_acc: 0.8602\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1826 - acc: 0.9344 - val_loss: 0.3396 - val_acc: 0.8914\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1868 - acc: 0.9384 - val_loss: 0.3939 - val_acc: 0.8968\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2039 - acc: 0.9363 - val_loss: 0.3668 - val_acc: 0.9074\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1676 - acc: 0.9414 - val_loss: 0.2577 - val_acc: 0.9023\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2006 - acc: 0.9362 - val_loss: 0.3828 - val_acc: 0.8928\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1526 - acc: 0.9444 - val_loss: 0.3386 - val_acc: 0.9046\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1569 - acc: 0.9464 - val_loss: 0.6617 - val_acc: 0.8789\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.2104 - acc: 0.9416 - val_loss: 0.7760 - val_acc: 0.8663\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1483 - acc: 0.9419 - val_loss: 0.4069 - val_acc: 0.8951\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1469 - acc: 0.9480 - val_loss: 0.5114 - val_acc: 0.8951\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1791 - acc: 0.9418 - val_loss: 0.4897 - val_acc: 0.89961s -\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1634 - acc: 0.9457 - val_loss: 0.7011 - val_acc: 0.8911\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1728 - acc: 0.9429 - val_loss: 0.4513 - val_acc: 0.8999\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.1565 - acc: 0.9445 - val_loss: 0.3651 - val_acc: 0.8965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6e3962898>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2. With 64 LSTM Units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 1.2364 - acc: 0.4732 - val_loss: 1.0499 - val_acc: 0.5813\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.9219 - acc: 0.5896 - val_loss: 0.8973 - val_acc: 0.5986\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.7434 - acc: 0.6790 - val_loss: 0.7699 - val_acc: 0.6882\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.6109 - acc: 0.7408 - val_loss: 0.6081 - val_acc: 0.7910\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.4734 - acc: 0.8361 - val_loss: 0.7770 - val_acc: 0.7808\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.3605 - acc: 0.8830 - val_loss: 0.5162 - val_acc: 0.8571\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.2978 - acc: 0.9109 - val_loss: 0.4848 - val_acc: 0.8768\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 35s 5ms/step - loss: 0.2614 - acc: 0.9174 - val_loss: 0.3824 - val_acc: 0.8717\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.2165 - acc: 0.9270 - val_loss: 0.6313 - val_acc: 0.8622\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.2211 - acc: 0.9332 - val_loss: 0.7563 - val_acc: 0.8575\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.2020 - acc: 0.9380 - val_loss: 0.7497 - val_acc: 0.8432\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1892 - acc: 0.9380 - val_loss: 0.4028 - val_acc: 0.8812\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1882 - acc: 0.9395 - val_loss: 0.3695 - val_acc: 0.9036\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1894 - acc: 0.9410 - val_loss: 0.3434 - val_acc: 0.9043\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1891 - acc: 0.9425 - val_loss: 0.4316 - val_acc: 0.8921\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1717 - acc: 0.9426 - val_loss: 0.3933 - val_acc: 0.8941\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1773 - acc: 0.9387 - val_loss: 0.4241 - val_acc: 0.9002\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1695 - acc: 0.9457 - val_loss: 0.3248 - val_acc: 0.9063\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1703 - acc: 0.9437 - val_loss: 0.3821 - val_acc: 0.9080\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1488 - acc: 0.9487 - val_loss: 0.4266 - val_acc: 0.8965\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1460 - acc: 0.9476 - val_loss: 0.3937 - val_acc: 0.9060\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1448 - acc: 0.9495 - val_loss: 0.5186 - val_acc: 0.8870\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1557 - acc: 0.9510 - val_loss: 0.4551 - val_acc: 0.9019\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1417 - acc: 0.9471 - val_loss: 0.4141 - val_acc: 0.9094\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1469 - acc: 0.9480 - val_loss: 0.4288 - val_acc: 0.8999\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1335 - acc: 0.9514 - val_loss: 0.3602 - val_acc: 0.9179\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1405 - acc: 0.9506 - val_loss: 0.3640 - val_acc: 0.9128\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1311 - acc: 0.9521 - val_loss: 0.5169 - val_acc: 0.9026\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1430 - acc: 0.9476 - val_loss: 0.3377 - val_acc: 0.9148\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.1300 - acc: 0.9533 - val_loss: 0.4458 - val_acc: 0.9094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6e95ec4a8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 511        0        26        0                   0   \n",
      "SITTING                  2      376       111        0                   0   \n",
      "STANDING                 0       67       463        1                   0   \n",
      "WALKING                  0        0         0      456                  15   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 418   \n",
      "WALKING_UPSTAIRS         0        0         0        1                  14   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           1  \n",
      "WALKING                           25  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 456  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 2s 599us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4458080819701784, 0.9093993892093655]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model 3 - 128 LSTM units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 128)               70656     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 71,430\n",
      "Trainable params: 71,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 63s 9ms/step - loss: 1.2960 - acc: 0.4306 - val_loss: 1.2994 - val_acc: 0.4625\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.8653 - acc: 0.6260 - val_loss: 0.7847 - val_acc: 0.6502\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.6582 - acc: 0.7353 - val_loss: 0.6637 - val_acc: 0.7520\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.5072 - acc: 0.8150 - val_loss: 0.6630 - val_acc: 0.7333\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.3659 - acc: 0.8791 - val_loss: 0.4133 - val_acc: 0.8585\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.2462 - acc: 0.9170 - val_loss: 0.3530 - val_acc: 0.8629\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.2139 - acc: 0.9300 - val_loss: 0.3659 - val_acc: 0.9043\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1893 - acc: 0.9357 - val_loss: 0.3783 - val_acc: 0.8928\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1882 - acc: 0.9392 - val_loss: 0.4104 - val_acc: 0.8931\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1727 - acc: 0.9400 - val_loss: 0.3657 - val_acc: 0.9040\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1453 - acc: 0.9495 - val_loss: 0.4346 - val_acc: 0.9046\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1586 - acc: 0.9440 - val_loss: 0.4312 - val_acc: 0.8918\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1458 - acc: 0.9475 - val_loss: 0.4586 - val_acc: 0.9036\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1492 - acc: 0.9472 - val_loss: 0.4406 - val_acc: 0.9135\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1477 - acc: 0.9476 - val_loss: 0.7404 - val_acc: 0.8856\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1393 - acc: 0.9513 - val_loss: 0.5410 - val_acc: 0.9023\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1553 - acc: 0.9480 - val_loss: 0.5414 - val_acc: 0.8955\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1476 - acc: 0.9514 - val_loss: 0.4589 - val_acc: 0.9033\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1383 - acc: 0.9505 - val_loss: 0.5552 - val_acc: 0.8914\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1546 - acc: 0.9426 - val_loss: 0.4748 - val_acc: 0.8897\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1354 - acc: 0.9490 - val_loss: 0.3471 - val_acc: 0.9182\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1349 - acc: 0.9506 - val_loss: 0.3687 - val_acc: 0.9125\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1325 - acc: 0.9525 - val_loss: 0.7346 - val_acc: 0.8904\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1457 - acc: 0.9520 - val_loss: 0.4050 - val_acc: 0.8996\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1896 - acc: 0.9361 - val_loss: 0.4694 - val_acc: 0.9026\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1558 - acc: 0.9429 - val_loss: 0.3899 - val_acc: 0.9125\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1324 - acc: 0.9490 - val_loss: 0.4893 - val_acc: 0.9101\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1270 - acc: 0.9531 - val_loss: 0.4550 - val_acc: 0.8951\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.1351 - acc: 0.9516 - val_loss: 0.4144 - val_acc: 0.9131\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 62s 8ms/step - loss: 0.2471 - acc: 0.9331 - val_loss: 0.3491 - val_acc: 0.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6ed863128>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 534        0         0        0                   0   \n",
      "SITTING                  1      387        98        0                   0   \n",
      "STANDING                 0      102       429        1                   0   \n",
      "WALKING                  0        0         0      441                  27   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 418   \n",
      "WALKING_UPSTAIRS         0        1         0        0                   0   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             3  \n",
      "SITTING                            5  \n",
      "STANDING                           0  \n",
      "WALKING                           28  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 470  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34914769746373947, 0.9090600610790635]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import L1L2\n",
    "from keras.models import load_model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import LSTM , BatchNormalization\n",
    "reg = L1L2(0.01, 0.01)\n",
    "from keras.initializers import he_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 128, 100)          44000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 100)          400       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 60)                38640     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 366       \n",
      "=================================================================\n",
      "Total params: 83,406\n",
      "Trainable params: 83,206\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "#neurons=100\n",
    "model.add(LSTM(100,input_shape=(timesteps,input_dim), kernel_initializer='glorot_normal',\n",
    " return_sequences=True, bias_regularizer=reg))\n",
    "model.add(BatchNormalization())\n",
    "#dropout =0.6\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(60))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(n_classes,activation='sigmoid'))\n",
    "#summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer='rmsprop',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 102s 14ms/step - loss: 2.2795 - acc: 0.6542 - val_loss: 2.0736 - val_acc: 0.6342\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.9479 - acc: 0.8498 - val_loss: 0.5123 - val_acc: 0.8599\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.3197 - acc: 0.9150 - val_loss: 0.3017 - val_acc: 0.8945\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.2457 - acc: 0.9206 - val_loss: 0.3127 - val_acc: 0.8941\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.2154 - acc: 0.9323 - val_loss: 0.3894 - val_acc: 0.8558\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.1925 - acc: 0.9294 - val_loss: 0.2482 - val_acc: 0.9101\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.1825 - acc: 0.9381 - val_loss: 0.3068 - val_acc: 0.9016\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.1755 - acc: 0.9389 - val_loss: 0.2350 - val_acc: 0.9152\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.1907 - acc: 0.9392 - val_loss: 0.2533 - val_acc: 0.9165\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.1718 - acc: 0.9426 - val_loss: 0.3413 - val_acc: 0.9050\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 100s 14ms/step - loss: 0.1616 - acc: 0.9404 - val_loss: 0.2424 - val_acc: 0.9223\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1565 - acc: 0.9412 - val_loss: 0.2935 - val_acc: 0.9091\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.1618 - acc: 0.9412 - val_loss: 0.3686 - val_acc: 0.9060\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.1778 - acc: 0.9414 - val_loss: 0.4008 - val_acc: 0.9162\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.1597 - acc: 0.9436 - val_loss: 0.3874 - val_acc: 0.8850\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 102s 14ms/step - loss: 0.1526 - acc: 0.9421 - val_loss: 0.4912 - val_acc: 0.8979\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 102s 14ms/step - loss: 0.1505 - acc: 0.9461 - val_loss: 0.3716 - val_acc: 0.9138\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 101s 14ms/step - loss: 0.1649 - acc: 0.9438 - val_loss: 0.2851 - val_acc: 0.9179\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 101s 14ms/step - loss: 0.1678 - acc: 0.9380 - val_loss: 0.4072 - val_acc: 0.9057\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 101s 14ms/step - loss: 0.1507 - acc: 0.9444 - val_loss: 0.3384 - val_acc: 0.9192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e6ed85ec18>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "Y_train,\n",
    "batch_size=batch_size,\n",
    "validation_data=(X_test, Y_test),\n",
    "epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  2      443        41        0                   0   \n",
      "STANDING                 0      135       397        0                   0   \n",
      "WALKING                  0        0         0      474                  10   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 415   \n",
      "WALKING_UPSTAIRS         0        0         0        4                  24   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            5  \n",
      "STANDING                           0  \n",
      "WALKING                           12  \n",
      "WALKING_DOWNSTAIRS                 5  \n",
      "WALKING_UPSTAIRS                 443  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 6s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3383917488639054, 0.9192399049881235]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import L1L2\n",
    "from keras.models import load_model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import LSTM , BatchNormalization\n",
    "reg = L1L2(0.01, 0.01)\n",
    "from keras.initializers import he_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hims1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\hims1\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 150)          96000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 150)          600       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 150)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 120)               130080    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 726       \n",
      "=================================================================\n",
      "Total params: 227,406\n",
      "Trainable params: 227,106\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "#neurons=120\n",
    "model.add(LSTM(150,input_shape=(timesteps,input_dim), kernel_initializer='glorot_normal',\n",
    " return_sequences=True, bias_regularizer=reg))\n",
    "model.add(BatchNormalization())\n",
    "#dropout =0.7\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(120))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(n_classes,activation='sigmoid'))\n",
    "#summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tensorboard/scalars_and_keras\n",
    "filepath=\"weights.best.hdf5\"\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "checkpoint_1 = ModelCheckpoint(filepath,\n",
    "                                monitor=\"val_acc\",\n",
    "                                mode=\"max\",\n",
    "                                save_best_only=True,\n",
    "                                verbose=1)\n",
    "tensorboard_1 = TensorBoard(log_dir='graph_one', batch_size=16,update_freq='epoch')\n",
    "callbacks_1 = [checkpoint_1,tensorboard_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer='rmsprop',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hims1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 182s 25ms/step - loss: 2.6794 - acc: 0.7799 - val_loss: 1.6204 - val_acc: 0.8928\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89277, saving model to weights.best.hdf5\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 181s 25ms/step - loss: 0.9586 - acc: 0.9165 - val_loss: 0.5848 - val_acc: 0.8887\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89277\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 180s 25ms/step - loss: 0.2616 - acc: 0.9163 - val_loss: 0.3214 - val_acc: 0.8996\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89277 to 0.89956, saving model to weights.best.hdf5\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 180s 25ms/step - loss: 0.1825 - acc: 0.9346 - val_loss: 0.3431 - val_acc: 0.8911\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89956\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 180s 25ms/step - loss: 0.1727 - acc: 0.9366 - val_loss: 0.5243 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89956\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 180s 24ms/step - loss: 0.1674 - acc: 0.9382 - val_loss: 0.3194 - val_acc: 0.9148\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.89956 to 0.91483, saving model to weights.best.hdf5\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1708 - acc: 0.9351 - val_loss: 0.2424 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.91483 to 0.92026, saving model to weights.best.hdf5\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 198s 27ms/step - loss: 0.1628 - acc: 0.9391 - val_loss: 0.6612 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.92026\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 195s 26ms/step - loss: 0.1899 - acc: 0.9321 - val_loss: 0.2953 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.92026\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 192s 26ms/step - loss: 0.1654 - acc: 0.9372 - val_loss: 0.3168 - val_acc: 0.9155\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.92026\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 188s 26ms/step - loss: 0.1631 - acc: 0.9355 - val_loss: 0.3804 - val_acc: 0.8992\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.92026\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 181s 25ms/step - loss: 0.1474 - acc: 0.9437 - val_loss: 0.3639 - val_acc: 0.9325\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.92026 to 0.93247, saving model to weights.best.hdf5\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 181s 25ms/step - loss: 0.1580 - acc: 0.9414 - val_loss: 0.3887 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93247\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 182s 25ms/step - loss: 0.1579 - acc: 0.9433 - val_loss: 0.2951 - val_acc: 0.9016\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93247\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 181s 25ms/step - loss: 0.1612 - acc: 0.9416 - val_loss: 0.4610 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93247\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 182s 25ms/step - loss: 0.1530 - acc: 0.9433 - val_loss: 0.3265 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93247\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 182s 25ms/step - loss: 0.1535 - acc: 0.9464 - val_loss: 0.6074 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.93247\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 181s 25ms/step - loss: 0.1456 - acc: 0.9470 - val_loss: 0.5414 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.93247\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 182s 25ms/step - loss: 0.1579 - acc: 0.9410 - val_loss: 0.3574 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.93247\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 183s 25ms/step - loss: 0.1613 - acc: 0.9422 - val_loss: 0.3894 - val_acc: 0.9087\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.93247\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(X_train,\n",
    "Y_train,\n",
    "batch_size=batch_size,\n",
    "validation_data=(X_test, Y_test),\n",
    "epochs=20,\n",
    "callbacks=callbacks_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  4      401        84        0                   0   \n",
      "STANDING                 0      116       416        0                   0   \n",
      "WALKING                  0        1         0      465                  23   \n",
      "WALKING_DOWNSTAIRS       0        2         0        0                 415   \n",
      "WALKING_UPSTAIRS         0       19         0        3                   5   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                            7  \n",
      "WALKING_DOWNSTAIRS                 3  \n",
      "WALKING_UPSTAIRS                 444  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128, 150)          96000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 150)          600       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 150)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 120)               130080    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 726       \n",
      "=================================================================\n",
      "Total params: 227,406\n",
      "Trainable params: 227,106\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "#neurons=120\n",
    "model.add(LSTM(150,input_shape=(timesteps,input_dim), kernel_initializer='glorot_normal',\n",
    " return_sequences=True, bias_regularizer=reg))\n",
    "model.add(BatchNormalization())\n",
    "#dropout =0.7\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(120))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(n_classes,activation='sigmoid'))\n",
    "#summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"weights.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer='rmsprop',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 12s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36393380713630763, 0.9324737020699015]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of  Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------------------+---------------+-----------+\n",
      "| Sr. No. |             Model Name             | Test Accuracy | Test loss |\n",
      "+---------+------------------------------------+---------------+-----------+\n",
      "|    1    |     1 layer with 40 LSTM Units     |      0.90     |    0.30   |\n",
      "|    2    |     1 layer with 64 LSTM units     |      0.91     |    0.39   |\n",
      "|    3    |    1 layer with 128 LSTM units     |      0.92     |    0.47   |\n",
      "|    4    | 2 layers with 100 & 60 LSTM units  |      0.92     |    0.30   |\n",
      "|    5    | 2 layers with 150 & 120 LSTM units |      0.93     |    0.36   |\n",
      "+---------+------------------------------------+---------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable \n",
    "x = PrettyTable() \n",
    "x.field_names = [\"Sr. No.\",\"Model Name\", \"Test Accuracy\", \"Test loss\"] \n",
    "x.add_row([\"1\",\"1 layer with 40 LSTM Units\",\"0.90\", \"0.30\"]) \n",
    "x.add_row([\"2\",\"1 layer with 64 LSTM units\",\"0.91\", \"0.39\"]) \n",
    "x.add_row([\"3\",\"1 layer with 128 LSTM units\",\"0.92\", \"0.47\"]) \n",
    "x.add_row([\"4\",\"2 layers with 100 & 60 LSTM units\",\"0.92\", \"0.30\"]) \n",
    "x.add_row([\"5\",\"2 layers with 150 & 120 LSTM units\",\"0.93\", \"0.36\"])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  We were able to acheive best accuracy with model 5 which has 2 layers of LSTM with 150 & 120 units.\n",
    "\n",
    "\n",
    "\n",
    "2. We got a Test accuracy of 93.25% & Test loss of 0.36 using the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
